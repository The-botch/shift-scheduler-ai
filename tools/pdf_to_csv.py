#!/usr/bin/env python3
"""
ã™ã¹ã¦ã®ã‚·ãƒ•ãƒˆPDFã‚’å¤‰æ›ã—ã¦1ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å†å¸°çš„ã«å‡¦ç†
"""

import pdfplumber
import csv
import re
from pathlib import Path
import sys
import unicodedata


def normalize_staff_name(name):
    """
    ã‚¹ã‚¿ãƒƒãƒ•åã‚’æ­£è¦åŒ–ã—ã¦é‡è¤‡ã‚’é˜²ã
    - Unicodeæ­£è¦åŒ–ï¼ˆNFKCï¼‰ã§ç•°ä½“å­—ã‚’çµ±ä¸€
    - ã€Œï¼ˆç¤¾å“¡ï¼‰ã€ã€Œ(ç¤¾å“¡)ã€ã‚’å‰Šé™¤
    - å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    """
    if not name:
        return ""

    # Unicodeæ­£è¦åŒ–ï¼ˆNFKC: äº’æ›æ–‡å­—ã‚’æ¨™æº–å½¢ã«å¤‰æ›ï¼‰
    normalized = unicodedata.normalize('NFKC', name)

    # ã€Œï¼ˆç¤¾å“¡ï¼‰ã€ã€Œ(ç¤¾å“¡)ã€ã‚’å‰Šé™¤
    normalized = normalized.replace('ï¼ˆç¤¾å“¡ï¼‰', '').replace('(ç¤¾å“¡)', '')
    normalized = normalized.replace('ç¤¾å“¡', '')  # æ‹¬å¼§ãªã—ã®ã€Œç¤¾å“¡ã€ã‚‚å‰Šé™¤

    # å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    normalized = normalized.strip()

    return normalized


def pdf_to_data_rows(pdf_path):
    """
    PDFã‹ã‚‰è¡Œãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    """
    rows = []

    try:
        with pdfplumber.open(pdf_path) as pdf:
            # æœ€åˆã®ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†
            first_page = pdf.pages[0]
            text = first_page.extract_text()

            if not text:
                print(f"  âš ï¸  Warning: Could not extract text from {pdf_path.name}")
                return rows

            # PDFãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰åº—èˆ—æƒ…å ±ã¨å¹´æœˆã‚’æŠ½å‡º
            filename = pdf_path.stem
            # ä¾‹: ã‚·ãƒ•ãƒˆè¡¨_20251001-20251031_Stand+Banh+Mi
            # ã¾ãŸã¯: æ”¹3ã‚·ãƒ•ãƒˆè¡¨_20251001-20251031_Atelier
            parts = filename.split('_')
            if len(parts) >= 3:
                date_range = parts[1]  # 20251001-20251031
                store_name_raw = parts[2].replace('+', ' ')  # Stand Banh Mi

                # å¹´æœˆã‚’æŠ½å‡º
                year_month_start = date_range.split('-')[0][:6]  # 202510
                plan_year = year_month_start[:4]  # 2025
                plan_month = year_month_start[4:6]  # 10
            else:
                plan_year = "2025"
                plan_month = "10"
                store_name_raw = "Unknown"

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã—ã¦æŠ½å‡ºã‚’è©¦ã¿ã‚‹
            tables = first_page.extract_tables()

            if not tables:
                return rows

            # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ
            for table in tables:
                if not table:
                    continue

                # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼ˆã‚¹ã‚¿ãƒƒãƒ•åï¼‰
                header_row = table[0] if table else []
                staff_names = []

                # ä¸è¦ãªåˆ—åã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆåº—èˆ—åã‚„å‹¤å‹™åœ°åã‚’å«ã‚€ï¼‰
                skip_keywords = ['æ—¥ä»˜', 'è‡ªç”±ãƒ¶ä¸˜', 'è‡ªç”±ãŒä¸˜', 'ç¥å¤©å¯º', 'å­¦å¤§', 'å­¦â¼¤', 'éº»å¸ƒå°', 'â¿‡å¸ƒå°', 'æ¸‹è°·', 'æ¸‹â¾•',
                                'ã®ã‚·ãƒ•ãƒˆ', 'L\'Atelier', 'Stand', 'Banh', 'Mi', 'COME', 'SHIBUYA', 'Bo', 'Bun']

                for cell in header_row:
                    if cell and cell.strip():
                        # ã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ã‹ãƒã‚§ãƒƒã‚¯
                        should_skip = any(keyword in cell for keyword in skip_keywords)
                        if should_skip:
                            continue

                        # ç¤¾å“¡åŒºåˆ†ã‚’åˆ¤å®šï¼ˆæ­£è¦åŒ–å‰ã®å…ƒãƒ‡ãƒ¼ã‚¿ã§åˆ¤å®šï¼‰
                        is_employee = '(ç¤¾å“¡)' in cell or 'ç¤¾å“¡' in cell or 'ï¼ˆç¤¾å“¡ï¼‰' in cell

                        # åå‰ã‚’æ­£è¦åŒ–
                        name = normalize_staff_name(cell)

                        if name and name not in ['æ—¥ä»˜ / æ—¥', '']:
                            staff_names.append({
                                'name': name,
                                'is_employee': 'ç¤¾å“¡' if is_employee else 'ã‚¢ãƒ«ãƒã‚¤ãƒˆ'
                            })

                # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å‡¦ç†
                for row in table[1:]:
                    if not row or len(row) < 2:
                        continue

                    # æ—¥ä»˜ã‚»ãƒ«ã‚’è§£æ
                    date_cell = row[0]
                    if not date_cell:
                        continue

                    date_match = re.match(r'(\d+/\d+)\s*\(([^\)]+)\)', str(date_cell))
                    if not date_match:
                        continue

                    date_str = date_match.group(1)
                    weekday = date_match.group(2)

                    # æ—¥ä»˜ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (2025-10-01 å½¢å¼)
                    month, day = date_str.split('/')
                    full_date = f"{plan_year}-{month.zfill(2)}-{day.zfill(2)}"

                    # å„ã‚¹ã‚¿ãƒƒãƒ•ã®ã‚·ãƒ•ãƒˆã‚»ãƒ«ã‚’å‡¦ç†
                    for i, cell in enumerate(row[1:], start=0):
                        if i >= len(staff_names):
                            break

                        if not cell or cell.strip() in ['/', '-', '']:
                            continue

                        staff = staff_names[i]
                        cell_text = str(cell).strip()

                        # æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
                        time_pattern = r'(\d{1,2}:\d{2})ã€œ(\d{1,2}:\d{2})'
                        time_matches = re.findall(time_pattern, cell_text)

                        if time_matches:
                            for start_time, end_time in time_matches:
                                # å‹¤å‹™å ´æ‰€ã‚’æŠ½å‡ºï¼ˆæ™‚é–“ã®å‰ã«ã‚ã‚‹æ–‡å­—åˆ—ï¼‰
                                location_match = re.search(r'([^\d:]+)(?=\d{1,2}:\d{2})', cell_text)
                                location = location_match.group(1).strip() if location_match else ""

                                # é›‡ç”¨å½¢æ…‹ã‚’è‹±èªåŒ–
                                employment_type_en = 'MONTHLY' if staff['is_employee'] == 'ç¤¾å“¡' else 'HOURLY'

                                # ä¼‘æ†©æ™‚é–“ã‚’è¨ˆç®—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ60åˆ†ã€5æ™‚é–“ä»¥ä¸‹ãªã‚‰0åˆ†ï¼‰
                                # æ™‚é–“ã‚’åˆ†ã«å¤‰æ›
                                start_parts = start_time.split(':')
                                end_parts = end_time.split(':')
                                start_minutes = int(start_parts[0]) * 60 + int(start_parts[1])
                                end_minutes = int(end_parts[0]) * 60 + int(end_parts[1])

                                # çµ‚äº†æ™‚åˆ»ãŒç¿Œæ—¥ã«ã¾ãŸãŒã‚‹å ´åˆï¼ˆä¾‹: 27:00ï¼‰
                                if end_minutes < start_minutes:
                                    end_minutes += 24 * 60

                                work_duration_minutes = end_minutes - start_minutes

                                # 5æ™‚é–“ï¼ˆ300åˆ†ï¼‰ä»¥ä¸‹ãªã‚‰ä¼‘æ†©ãªã—ã€è¶…ãˆã‚‹å ´åˆã¯60åˆ†ä¼‘æ†©
                                break_mins = 0 if work_duration_minutes <= 300 else 60

                                rows.append({
                                    'tenant_code': 'STAND_BANH_MI',  # å›ºå®šå€¤ï¼ˆå¾Œã§èª¿æ•´å¯èƒ½ï¼‰
                                    'store_name': store_name_raw,
                                    'plan_year': plan_year,
                                    'plan_month': plan_month,
                                    'shift_date': full_date,
                                    'staff_name': staff['name'],
                                    'employment_type': employment_type_en,
                                    'work_location': location,
                                    'start_time': start_time,
                                    'end_time': end_time,
                                    'break_minutes': break_mins,
                                    'notes': ''
                                })

    except Exception as e:
        print(f"  âŒ Error processing {pdf_path.name}: {str(e)}")

    return rows


def convert_all_pdfs_to_single_csv(pdf_root_dir, output_csv):
    """
    æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé…ä¸‹ã®ã™ã¹ã¦ã®PDFã‚’1ã¤ã®CSVã«ã¾ã¨ã‚ã‚‹
    """
    pdf_root = Path(pdf_root_dir)

    if not pdf_root.exists():
        print(f"Error: Directory not found: {pdf_root_dir}")
        return False

    # ã™ã¹ã¦ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«å–å¾—
    pdf_files = sorted(pdf_root.rglob("*.pdf"))

    if not pdf_files:
        print(f"No PDF files found in {pdf_root_dir}")
        return False

    print(f"\n{'='*60}")
    print(f"ğŸ”„ PDFâ†’CSVä¸€æ‹¬å¤‰æ›ï¼†çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print(f"{'='*60}\n")
    print(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {pdf_root}")
    print(f"å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«: {output_csv}")
    print(f"æ¤œå‡ºPDFãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(pdf_files)}\n")

    # çµ±åˆç”¨ã®ãƒ‡ãƒ¼ã‚¿
    all_rows = []

    for pdf_file in pdf_files:
        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¡¨ç¤º
        rel_path = pdf_file.relative_to(pdf_root)
        print(f"å‡¦ç†ä¸­: {rel_path}")

        # PDFã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        rows = pdf_to_data_rows(pdf_file)
        all_rows.extend(rows)

        print(f"  âœ… {len(rows)} ã‚·ãƒ•ãƒˆæŠ½å‡º")

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    output_path = Path(output_csv)
    fieldnames = [
        'tenant_code', 'store_name', 'plan_year', 'plan_month',
        'shift_date', 'staff_name', 'employment_type', 'work_location',
        'start_time', 'end_time', 'break_minutes', 'notes'
    ]

    with open(output_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(all_rows)

    print(f"\n{'='*60}")
    print(f"âœ… å¤‰æ›ãƒ»çµ±åˆå®Œäº†ï¼")
    print(f"{'='*60}\n")
    print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
    print(f"ç·ã‚·ãƒ•ãƒˆä»¶æ•°: {len(all_rows):,} ä»¶\n")

    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    print("ğŸ“Š çµ±è¨ˆæƒ…å ±:")

    # åº—èˆ—åˆ¥é›†è¨ˆ
    store_counts = {}
    for row in all_rows:
        store = row['store_name']
        store_counts[store] = store_counts.get(store, 0) + 1

    print("\n  åº—èˆ—åˆ¥ã‚·ãƒ•ãƒˆä»¶æ•°:")
    for store, count in sorted(store_counts.items()):
        print(f"    {store}: {count:,} ä»¶")

    # å¹´æœˆåˆ¥é›†è¨ˆ
    period_counts = {}
    for row in all_rows:
        period = f"{row['plan_year']}-{row['plan_month'].zfill(2)}"
        period_counts[period] = period_counts.get(period, 0) + 1

    print("\n  å¹´æœˆåˆ¥ã‚·ãƒ•ãƒˆä»¶æ•°:")
    for period, count in sorted(period_counts.items()):
        print(f"    {period}: {count:,} ä»¶")

    # é›‡ç”¨å½¢æ…‹åˆ¥é›†è¨ˆ
    employment_counts = {}
    for row in all_rows:
        emp_type = row['employment_type']
        employment_counts[emp_type] = employment_counts.get(emp_type, 0) + 1

    print("\n  é›‡ç”¨å½¢æ…‹åˆ¥ã‚·ãƒ•ãƒˆä»¶æ•°:")
    for emp_type, count in sorted(employment_counts.items()):
        print(f"    {emp_type}: {count:,} ä»¶")

    print(f"\n{'='*60}\n")

    return True


if __name__ == "__main__":
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ•ã‚¡ã‚¤ãƒ«å
    default_pdf_dir = Path(__file__).parent.parent / "fixtures" / "shift_pdfs" / "pdf_output"
    default_csv_output = Path(__file__).parent.parent / "fixtures" / "shift_pdfs" / "csv_output" / "ã‚·ãƒ•ãƒˆ.csv"

    pdf_dir = sys.argv[1] if len(sys.argv) > 1 else default_pdf_dir
    csv_output = sys.argv[2] if len(sys.argv) > 2 else default_csv_output

    if convert_all_pdfs_to_single_csv(pdf_dir, csv_output):
        print("âœ… å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚")
        print(f"\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        print(f"  {csv_output}\n")
    else:
        print("âŒ å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)
